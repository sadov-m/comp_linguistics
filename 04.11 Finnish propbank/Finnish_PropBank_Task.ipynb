{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_data(path):\n",
    "    \n",
    "    with open(path, encoding='utf-8') as rdata:\n",
    "        lines = rdata.read().split('\\n')\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def process_the_data(path):\n",
    "    ID = []\n",
    "    pos = []\n",
    "    feats = []  # not included\n",
    "    head = []\n",
    "    deprel = []\n",
    "    deprels = []  # target\n",
    "\n",
    "    lines = open_data(path)\n",
    "    \n",
    "    for line in lines:\n",
    "    \n",
    "        string = line.split('\\t')\n",
    "    \n",
    "        if len(string) != 1:\n",
    "            ID.append(int(string[0]))\n",
    "            pos.append(string[3])\n",
    "            feats.append(string[5])\n",
    "            head.append(int(string[6]))\n",
    "            deprel.append(string[7])\n",
    "            deprels.append([''.join(elem.split(':')[1:]) for elem in string[8].split('|')])\n",
    "            #print([''.join(elem.split(':')[1:]) for elem in string[8].split('|')])\n",
    "    \n",
    "    predictors = [pos[:], deprel[:]]\n",
    "    \n",
    "    return predictors, deprels[:], ID[:], head[:]\n",
    "\n",
    "train_x, train_y, train_id, train_head = process_the_data('fipb-ud-train.conllu')\n",
    "dev_x, dev_y, dev_id, dev_head = process_the_data('fipb-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"ID\", \"TOKEN\", \"LEM\", \"POS\", \"POSABBR\", \"FEATS\", \"HEAD\", \"DEPREL\", \"DEPRELS\", \"MISC\"]\n",
    "\n",
    "def transform_data(fit, fit_y, predict, predict_y):  # partially void method! beware!\n",
    "    \n",
    "    for i in range(len(fit)):\n",
    "        \n",
    "        lb = LabelEncoder()\n",
    "        fit[i] = lb.fit_transform(fit[i])\n",
    "        predict[i] = lb.transform(predict[i])\n",
    "        #print(predictors[i])\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    fit_y = mlb.fit_transform(fit_y)\n",
    "    predict_y = mlb.transform(predict_y)\n",
    "    \n",
    "    return fit_y, predict_y\n",
    "\n",
    "train_y, dev_y = transform_data(train_x, train_y, dev_x, dev_y)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_X(*args):\n",
    "    X = []\n",
    "    \n",
    "    for i in range(len(args[0])):  # assuming they are all even in terms of length\n",
    "        X.append([])\n",
    "        for arg in args:\n",
    "            X[-1].append(arg[i])\n",
    "    \n",
    "    return X\n",
    "            \n",
    "X = make_X(train_id, train_x[0], train_head, train_x[1])\n",
    "X_check = make_X(dev_id, dev_x[0], dev_head, dev_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, train_y)\n",
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10832395  0.23324435  0.1091725   0.54925921]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68737037441327364"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_check, dev_y)\n",
    "#print(train_x[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
